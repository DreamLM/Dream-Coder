# EvalPlus è¯„ä¼°æç¤ºå‡†å¤‡è„šæœ¬

æœ¬æ–‡ä»¶å¤¹åŒ…å«ç”¨äºå‡†å¤‡ EvalPlus åŸºå‡†æµ‹è¯•æç¤ºçš„è„šæœ¬ï¼Œæ”¯æŒ HumanEval+ã€MBPP+ å’Œ EvalPerf æ•°æ®é›†ã€‚

## è„šæœ¬è¯´æ˜

### 1. `prepare_eval_prompts.py` - å®Œæ•´ç‰ˆæœ¬

å‡†å¤‡åŒ…å«æ‰€æœ‰å…ƒæ•°æ®çš„å®Œæ•´è¯„ä¼°æç¤ºï¼Œé€‚ç”¨äºæ·±åº¦åˆ†æå’Œè¯„ä¼°ã€‚

**ç”¨æ³•ç¤ºä¾‹ï¼š**
```bash
# ç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®é›†çš„å®Œæ•´æç¤º
python3 prepare_eval_prompts.py --output all_eval_prompts.jsonl

# åªç”Ÿæˆ HumanEval+ å’Œ MBPP+
python3 prepare_eval_prompts.py --output humaneval_mbpp.jsonl --no-evalperf

# ä½¿ç”¨ mini ç‰ˆæœ¬ï¼ˆæ›´å¿«ï¼‰
python3 prepare_eval_prompts.py --mini --output eval_prompts_mini.jsonl

# åªæŸ¥çœ‹æ‘˜è¦ï¼Œä¸ä¿å­˜æ–‡ä»¶
python3 prepare_eval_prompts.py --summary-only
```

**è¾“å‡ºæ ¼å¼ï¼š**
```json
{
  "task_id": "HumanEval/0",
  "dataset": "humaneval_plus",
  "prompt": "def has_close_elements(...)...",
  "entry_point": "has_close_elements",
  "canonical_solution": "...",
  "test_input_count": 1006,
  "contract": "...",
  "metadata": {
    "atol": 0,
    "has_base_input": true,
    "has_plus_input": true
  }
}
```

### 2. `prepare_simple_prompts.py` - ç®€åŒ–ç‰ˆæœ¬

åªæå–ä»£ç ç”Ÿæˆå¿…éœ€çš„åŸºæœ¬å­—æ®µï¼Œæ›´é€‚åˆ LLM æ¨ç†ã€‚

**ç”¨æ³•ç¤ºä¾‹ï¼š**
```bash
# ç”Ÿæˆç®€åŒ–çš„æ‰€æœ‰æ•°æ®é›†æç¤º
python3 prepare_simple_prompts.py --output simple_prompts.jsonl

# åªç”Ÿæˆ HumanEval+
python3 prepare_simple_prompts.py --humaneval-only --output humaneval_only.jsonl

# åªç”Ÿæˆ MBPP+
python3 prepare_simple_prompts.py --mbpp-only --output mbpp_only.jsonl

# æ’é™¤ EvalPerf
python3 prepare_simple_prompts.py --no-evalperf --output no_evalperf.jsonl
```

**è¾“å‡ºæ ¼å¼ï¼š**
```json
{
  "task_id": "HumanEval/0",
  "dataset": "humaneval_plus",
  "prompt": "def has_close_elements(...)...",
  "entry_point": "has_close_elements"
}
```

### 3. `prepare_instruct_prompts.py` - Instructæ¨¡å‹ä¸“ç”¨ ğŸ†•

ä¸“é—¨ä¸ºinstructæ¨¡å‹å‡†å¤‡HuggingFace messagesæ ¼å¼çš„è¯„ä¼°æç¤ºï¼Œå®Œå…¨å…¼å®¹chat templateã€‚

**ç”¨æ³•ç¤ºä¾‹ï¼š**
```bash
# ç”Ÿæˆé»˜è®¤æ¨¡æ¿çš„instructæ ¼å¼
python3 prepare_instruct_prompts.py --output instruct_default.jsonl

# ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–æ¨¡æ¿
python3 prepare_instruct_prompts.py --template perf-instruct --output instruct_perf.jsonl

# ä½¿ç”¨ä¸­æ–‡æ¨¡æ¿
python3 prepare_instruct_prompts.py --template chinese --output instruct_chinese.jsonl

# åŒ…å«responseæ¨¡æ¿ï¼ˆç”¨äºfew-shotæˆ–continuationï¼‰
python3 prepare_instruct_prompts.py --include-response --output instruct_with_response.jsonl

# ä½¿ç”¨è‡ªå®šä¹‰instruction
python3 prepare_instruct_prompts.py --custom-instruction "Write Python code to solve:" --output custom.jsonl

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡æ¿
python3 prepare_instruct_prompts.py --show-templates
```

**è¾“å‡ºæ ¼å¼ï¼š**
```json
{
  "task_id": "HumanEval/0",
  "dataset": "humaneval_plus",
  "messages": [
    {
      "role": "user",
      "content": "Please provide a self-contained Python script that solves the following problem in a markdown code block:\n```python\ndef has_close_elements(...)...\n```"
    },
    {
      "role": "assistant",
      "content": "Below is a Python script with a self-contained function that solves the problem and passes corresponding tests:\n```python\n"
    }
  ],
  "entry_point": "has_close_elements",
  "instruction_template": "default",
  "metadata": {
    "original_prompt": "def has_close_elements(...)...",
    "has_response_template": true
  }
}
```

### 4. `demo_usage.py` - ä½¿ç”¨æ¼”ç¤º

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç”Ÿæˆçš„å„ç§æ ¼å¼æ•°æ®ï¼ŒåŒ…æ‹¬ä¸transformersåº“çš„é›†æˆã€‚

```bash
python3 demo_usage.py
```

## å¯ç”¨çš„Instructionæ¨¡æ¿

| æ¨¡æ¿åç§° | æè¿° | é€‚ç”¨åœºæ™¯ |
|---------|------|----------|
| `default` | æ ‡å‡†è‹±æ–‡æ¨¡æ¿ | é€šç”¨ä»£ç ç”Ÿæˆä»»åŠ¡ |
| `perf-instruct` | æ€§èƒ½ä¼˜åŒ–è‹±æ–‡æ¨¡æ¿ | å¼ºè°ƒæ•ˆç‡çš„ä»»åŠ¡ |
| `perf-CoT` | æ€ç»´é“¾+æ€§èƒ½ä¼˜åŒ–æ¨¡æ¿ | å¤æ‚ç®—æ³•é—®é¢˜ |
| `chinese` | ä¸­æ–‡æ¨¡æ¿ | ä¸­æ–‡æ¨¡å‹ |
| `chinese-perf` | ä¸­æ–‡æ€§èƒ½ä¼˜åŒ–æ¨¡æ¿ | ä¸­æ–‡æ¨¡å‹+æ€§èƒ½è¦æ±‚ |

## å‘½ä»¤è¡Œå‚æ•°

### é€šç”¨å‚æ•°
- `--output, -o`: è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `--summary-only`: åªæ˜¾ç¤ºæ‘˜è¦ï¼Œä¸ä¿å­˜æ–‡ä»¶
- `--mini`: ä½¿ç”¨ mini ç‰ˆæœ¬æ•°æ®é›†ï¼ˆå¦‚æœå¯ç”¨ï¼‰

### æ•°æ®é›†é€‰æ‹©
- `--no-humaneval`: ä¸åŒ…å« HumanEval+ æ•°æ®é›†
- `--no-mbpp`: ä¸åŒ…å« MBPP+ æ•°æ®é›†
- `--no-evalperf`: ä¸åŒ…å« EvalPerf æ•°æ®é›†
- `--humaneval-only`: åªåŒ…å« HumanEval+ æ•°æ®é›†
- `--mbpp-only`: åªåŒ…å« MBPP+ æ•°æ®é›†
- `--evalperf-only`: åªåŒ…å« EvalPerf æ•°æ®é›†

### Instructæ¨¡å‹ç‰¹æœ‰å‚æ•°
- `--template, -t`: é€‰æ‹©instructionæ¨¡æ¿
- `--custom-instruction`: ä½¿ç”¨è‡ªå®šä¹‰instruction prefix
- `--include-response`: åŒ…å«assistant responseçš„å¼€å¤´æ¨¡æ¿
- `--show-templates`: æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨æ¨¡æ¿

## æ•°æ®é›†ç»Ÿè®¡

- **HumanEval+**: 164 ä¸ªç¼–ç¨‹ä»»åŠ¡
- **MBPP+**: 378 ä¸ªç¼–ç¨‹ä»»åŠ¡
- **EvalPerf**: 118 ä¸ªæ€§èƒ½æµ‹è¯•ä»»åŠ¡
- **æ€»è®¡**: 660 ä¸ªä»»åŠ¡

## ç”Ÿæˆçš„æ–‡ä»¶

è¿è¡Œè„šæœ¬åä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

1. `eval_prompts_all.jsonl` - åŒ…å«æ‰€æœ‰æ•°æ®é›†çš„å®Œæ•´æç¤ºï¼ˆ660ä¸ªä»»åŠ¡ï¼‰
2. `simple_eval_prompts.jsonl` - ç®€åŒ–ç‰ˆæœ¬çš„æ‰€æœ‰æ•°æ®é›†æç¤º
3. `humaneval_prompts.jsonl` - åªåŒ…å« HumanEval+ çš„æç¤º
4. `instruct_default.jsonl` - Instructæ ¼å¼çš„é»˜è®¤æ¨¡æ¿æç¤º
5. `instruct_perf.jsonl` - Instructæ ¼å¼çš„æ€§èƒ½ä¼˜åŒ–æ¨¡æ¿æç¤º
6. `instruct_chinese.jsonl` - Instructæ ¼å¼çš„ä¸­æ–‡æ¨¡æ¿æç¤º

## ä½¿ç”¨å»ºè®®

### ç”¨äº Base æ¨¡å‹ä»£ç ç”Ÿæˆ
æ¨èä½¿ç”¨ `prepare_simple_prompts.py`ï¼š

```bash
python3 prepare_simple_prompts.py --humaneval-only --output humaneval_for_base_model.jsonl
```

### ç”¨äº Instruct æ¨¡å‹ä»£ç ç”Ÿæˆ â­
æ¨èä½¿ç”¨ `prepare_instruct_prompts.py`ï¼š

```bash
# æ ‡å‡†ç”¨æ³•
python3 prepare_instruct_prompts.py --template default --output instruct_standard.jsonl

# æ€§èƒ½ä¼˜åŒ–ä»»åŠ¡
python3 prepare_instruct_prompts.py --template perf-instruct --output instruct_performance.jsonl

# ä¸­æ–‡æ¨¡å‹
python3 prepare_instruct_prompts.py --template chinese --output instruct_chinese.jsonl
```

### ä¸HuggingFace Transformersé›†æˆ

```python
from transformers import AutoTokenizer
import json

# åŠ è½½tokenizerå’Œæ•°æ®
tokenizer = AutoTokenizer.from_pretrained("your-instruct-model")

with open("instruct_default.jsonl") as f:
    task = json.loads(f.readline())

# ä½¿ç”¨chat templateæ ¼å¼åŒ–
formatted_prompt = tokenizer.apply_chat_template(
    task["messages"],
    tokenize=False,
    add_generation_prompt=True
)

# è¿›è¡Œæ¨ç†...
```

### ç”¨äºè¯¦ç»†è¯„ä¼°åˆ†æ
æ¨èä½¿ç”¨ `prepare_eval_prompts.py`ï¼ŒåŒ…å«å®Œæ•´çš„å…ƒæ•°æ®ç”¨äºåˆ†æï¼š

```bash
python3 prepare_eval_prompts.py --output complete_eval_data.jsonl
```

### å¿«é€Ÿæµ‹è¯•
ä½¿ç”¨ mini ç‰ˆæœ¬è¿›è¡Œå¿«é€ŸåŸå‹éªŒè¯ï¼š

```bash
python3 prepare_instruct_prompts.py --mini --humaneval-only --summary-only
```

## ä¾èµ–è¦æ±‚

ç¡®ä¿å·²å®‰è£… EvalPlus åŒ…ï¼š

```bash
pip install evalplus
# æˆ–è€…
pip install -e .  # å¦‚æœåœ¨ evalplus æºç ç›®å½•
```

## è¾“å‡ºæ–‡ä»¶æ ¼å¼

æ‰€æœ‰è¾“å‡ºæ–‡ä»¶éƒ½æ˜¯ JSONLï¼ˆJSON Linesï¼‰æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼Œå¯ä»¥ç”¨æ ‡å‡†å·¥å…·å¤„ç†ï¼š

```bash
# æŸ¥çœ‹æ–‡ä»¶å†…å®¹
head -n 5 instruct_default.jsonl

# ç»Ÿè®¡ä»»åŠ¡æ•°é‡
wc -l instruct_default.jsonl

# ç¾åŒ–æ˜¾ç¤ºç¬¬ä¸€ä¸ªä»»åŠ¡
head -n 1 instruct_default.jsonl | python3 -m json.tool
```

## ç‰¹åˆ«è¯´æ˜

### Instructæ¨¡å‹çš„ä¼˜åŠ¿

- **æ ‡å‡†åŒ–æ ¼å¼**: å®Œå…¨å…¼å®¹HuggingFaceçš„chat template
- **å¤šæ ·åŒ–æ¨¡æ¿**: æ”¯æŒä¸åŒåœºæ™¯å’Œè¯­è¨€çš„instructionæ¨¡æ¿
- **æ˜“äºé›†æˆ**: ç›´æ¥é…åˆtransformersåº“ä½¿ç”¨
- **éµå¾ªæœ€ä½³å®è·µ**: åŸºäºEvalPluså®˜æ–¹çš„instructionæ ¼å¼